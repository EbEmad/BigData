version: '3.8'

services:
  kafka:
    build: ./kafka
    container_name: kafka
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=INTERNAL://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_LOG_DIRS=/bitnami/kafka/data
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
    healthcheck:
      test: ["CMD-SHELL", "/opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list | cat"]
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "9092:9092"
    networks:
      - stream-processing
    volumes:
      - .:/app

  spark-master:
    image: docker.io/bitnami/spark:3
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - HADOOP_USER_NAME=root
      - KAFKA_BROKERS=kafka:9092
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - .:/app
      - ./jars_dir:/opt/bitnami/spark/ivy:z
    depends_on:
      - kafka
    networks:
      - stream-processing

  spark-worker:
    image: docker.io/bitnami/spark:3
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    volumes:
      - .:/app
    networks:
      - stream-processing
  spark-submit:
    image: docker.io/bitnami/spark:3
    container_name: spark-submit
    environment:
      - SPARK_MODE=client
      - SPARK_MASTER_URL=spark://spark-master:7077
      - KAFKA_BROKERS=kafka:9092
    depends_on:
      - spark-master
      - kafka
    volumes:
      - .:/app
    networks:
      - stream-processing
    command: ["bash", "-lc", "tail -f /dev/null"]
  postgres:
    image: postgres:latest
    container_name: postgres
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=test
    ports:
      - "5432:5432"

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    networks:
      - stream-processing

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml  # Prometheus configuration
    ports:
      - "9090:9090"
    networks:
      - spark-network

networks:
  stream-processing:
    driver: bridge