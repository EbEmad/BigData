{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f5fd98-b4ae-493c-85e7-feb67d6ef067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, datediff, lag, when, row_number\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb91fd6-9421-4627-865e-892916e94713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark=SparkSession.builder.appName(\"ReadmissionRiskPrediction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd80087-6316-4efe-9b56-4a36bf676fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ADMISSIONS.csv file into a DataFrame\n",
    "df=spark.read.format(\"csv\") \\\n",
    "    .option(\"header\",True) \\\n",
    "    .option(\"inferSchema\",True) \\\n",
    "    .load(\"hdfs://namenode:9000/data/ADMISSIONS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641e6b0-2131-406d-a345-253b2254af98",
   "metadata": {},
   "source": [
    "### Readmission Risk Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159971a8-6d9c-4dd2-8b3d-ea6830450004",
   "metadata": {},
   "source": [
    "#### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ba81a7f-0dc8-45e9-a82f-8df55821adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------+-------------------+-----------+\n",
      "|SUBJECT_ID|HADM_ID|LENGTH_OF_STAY|NUM_PREV_ADMISSIONS|READMISSION|\n",
      "+----------+-------+--------------+-------------------+-----------+\n",
      "|     10002|  20002|             5|                  0|          0|\n",
      "+----------+-------+--------------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert ADMITTIME and DISCHTIME to timestamps\n",
    "df=df.withColumn(\"ADMITTIME\",col(\"ADMITTIME\").cast(\"timestamp\")) \\\n",
    "     .withColumn(\"DISCHTIME\", col(\"DISCHTIME\").cast(\"timestamp\"))\n",
    "\n",
    "# Calculate length of stay in days\n",
    "df=df.withColumn(\"LENGTH_OF_STAY\",datediff(col(\"DISCHTIME\"),col(\"ADMITTIME\")))\n",
    "\n",
    "# Calculate number of previous admissions\n",
    "window_spec=Window.partitionBy(\"SUBJECT_ID\").orderBy(\"ADMITTIME\")\n",
    "df=df.withColumn(\"NUM_PREV_ADMISSIONS\",row_number().over(window_spec)-1)\n",
    "\n",
    "# Create the READMISSION label (1 if readmitted within 30 days, 0 otherwise)\n",
    "df=df.withColumn(\"READMISSION\",when(datediff(lag(\"ADMITTIME\").over(window_spec),col(\"DISCHTIME\"))<=30,1).otherwise(0))\n",
    "\n",
    "# Drop rows with null values (e.g., first admission for each patient)\n",
    "df = df.na.drop()\n",
    "# Show the prepared data\n",
    "df.select(\"SUBJECT_ID\", \"HADM_ID\", \"LENGTH_OF_STAY\", \"NUM_PREV_ADMISSIONS\", \"READMISSION\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b0b8436-81b4-44e1-bf0e-9f619065b4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|READMISSION|count|\n",
      "+-----------+-----+\n",
      "|          0|    1|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# Count the number of readmissions and non-readmissions\n",
    "readmission_counts=df.groupBy(\"READMISSION\").count()\n",
    "readmission_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd426636-de3b-4182-80da-864da8445fb0",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba2784b-cca3-48f1-9f8e-257d4266d720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|features |READMISSION|\n",
      "+---------+-----------+\n",
      "|[5.0,0.0]|0          |\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "# Define the feature columns\n",
    "feature_columns=[\"LENGTH_OF_STAY\", \"NUM_PREV_ADMISSIONS\"]\n",
    "# Assemble features into a vector\n",
    "assembler=VectorAssembler(inputCols=feature_columns,outputCol=\"features\")\n",
    "df=assembler.transform(df)\n",
    "\n",
    "# Show the DataFrame with features\n",
    "df.select(\"features\", \"READMISSION\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f833c33-0588-4fb9-a770-180cb6de3ed9",
   "metadata": {},
   "source": [
    "###  Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c48713-549f-4ba0-8220-d936f70a0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (70% training, 30% test)\n",
    "train_data,test_data=df.randomSplit([0.7,0.3],seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9938fd8b-b4e7-4493-b050-90fcde05f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Initialize the Logistic Regression model\n",
    "lr=LogisticRegression(featuresCol=\"features\",labelCol=\"READMISSION\")\n",
    "\n",
    "# Train the model\n",
    "lr_model=lr.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9942c99-5ef7-4dd4-8b0b-4b5f25e61e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: nan\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# make predictions on the test set\n",
    "predictions=lr_model.transform(test_data)\n",
    "\n",
    "# Initialize the evaluator\n",
    "evaluator=MulticlassClassificationEvaluator(labelCol=\"READMISSION\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a906a0-1358-47d6-9252-646c7ca8b7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#  Calculate precision\n",
    "precision=evaluator.setMetricName(\"weightedPrecision\").evaluate(predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall=evaluator.setMetricName(\"weightedRecall\").evaluate(predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_score=evaluator.setMetricName(\"f1\").evaluate(predictions)\n",
    "print(\"F1-Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730c16bc-2776-4270-a22c-6a4205e782d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|READMISSION|count|\n",
      "+-----------+-----+\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_stats=predictions.groupBy(\"READMISSION\").count()\n",
    "pred_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "788b816b-8049-4bfb-9172-e8c7037eea99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_stats2 = predictions.groupBy(\"prediction\").count()\n",
    "pred_stats2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6695f85c-81d2-4526-82cb-bf832e4cee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained Linear Regression model to a file\n",
    "model_save_path = \"hdfs://namenode:9000/models/readmission_risk_prediction_lr_model\"\n",
    "lr_model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958db14-f687-4d29-8e2b-20d5754c82d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
